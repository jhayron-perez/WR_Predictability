{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f8f764-d02a-47cd-9d3f-d6dc3e230f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ec0876-ac66-45de-9f1b-ddc8af868839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_dataset_3d(dataset, new_resolution):\n",
    "    \"\"\"\n",
    "    Regrid a 3D dataset (time, lat, lon) to a new resolution using linear interpolation.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (xarray.Dataset): Input dataset with dimensions (time, lat, lon).\n",
    "    new_resolution (float): Desired new resolution (e.g., 1.0 for 1Â°).\n",
    "\n",
    "    Returns:\n",
    "    xarray.Dataset: Regridded dataset.\n",
    "    \"\"\"\n",
    "    # Get original coordinates\n",
    "    lat = dataset['lat'].values\n",
    "    lon = dataset['lon'].values\n",
    "    time = dataset['time'].values\n",
    "\n",
    "    # Create new latitude and longitude coordinates\n",
    "    new_lat = np.arange(lat.min(), lat.max() + new_resolution, new_resolution)\n",
    "    new_lon = np.arange(lon.min(), lon.max() + new_resolution, new_resolution)\n",
    "\n",
    "    varname_nc = list(dataset.data_vars.keys())[0]\n",
    "    # Prepare interpolation for each time step\n",
    "    regridded_data = []\n",
    "    for t in range(len(time)):\n",
    "        # Extract 2D data slice for the current time step\n",
    "        data_slice = dataset[varname_nc].isel(time=t).values\n",
    "\n",
    "        # Define an interpolation function\n",
    "        interp_func = RegularGridInterpolator((lat, lon), data_slice, method='linear', bounds_error=False, fill_value=np.nan)\n",
    "        \n",
    "        # Create mesh grid for new coordinates\n",
    "        new_lon_grid, new_lat_grid = np.meshgrid(new_lon, new_lat)\n",
    "\n",
    "        # Apply the interpolation on the new grid\n",
    "        interpolated_slice = interp_func((new_lat_grid, new_lon_grid))\n",
    "\n",
    "        regridded_data.append(interpolated_slice)\n",
    "\n",
    "    # Stack the regridded data into a 3D array\n",
    "    regridded_data = np.stack(regridded_data, axis=0)\n",
    "\n",
    "    # Create a new xarray Dataset\n",
    "    regridded_dataset = xr.Dataset(\n",
    "        {\n",
    "            varname_nc: (['time', 'lat', 'lon'], regridded_data)\n",
    "        },\n",
    "        coords={\n",
    "            'time': time,\n",
    "            'lat': new_lat,\n",
    "            'lon': new_lon\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return regridded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98b5e748-bb2a-4d25-9292-5f69333f7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weekly_anoms = '/glade/derecho/scratch/jhayron/Data4Predictability/WeeklyAnoms_DetrendedStd_v3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0f2dd4-9158-4b62-9ff8-07015e681edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = np.sort(glob.glob(f'{path_weekly_anoms}*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ee9d86-7b27-470f-84b6-7435b9f6ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_vars = [list_files[i].split('/')[-1].split('.')[0] for i in range(len(list_files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931fb84a-bcf4-4578-b0c4-41b34ca9eab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IC_SODA',\n",
       " 'IT_SODA',\n",
       " 'MLD_SODA',\n",
       " 'OHC100_SODA',\n",
       " 'OHC200_SODA',\n",
       " 'OHC300_SODA',\n",
       " 'OHC50_SODA',\n",
       " 'OHC700_SODA',\n",
       " 'OLR_ERA5',\n",
       " 'SD_ERA5',\n",
       " 'SSH_SODA',\n",
       " 'SST_OISSTv2',\n",
       " 'SST_SODA',\n",
       " 'STL_1m_ERA5',\n",
       " 'STL_28cm_ERA5',\n",
       " 'STL_7cm_ERA5',\n",
       " 'STL_full_ERA5',\n",
       " 'SWVL_1m_ERA5',\n",
       " 'SWVL_28cm_ERA5',\n",
       " 'SWVL_7cm_ERA5',\n",
       " 'SWVL_full_ERA5',\n",
       " 'U10_ERA5',\n",
       " 'U200_ERA5',\n",
       " 'Z500_ERA5']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0002a790-ded1-4ecd-a9a3-d80117cd1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weekly_anoms_1dg = '/glade/derecho/scratch/jhayron/Data4Predictability/WeeklyAnoms_DetrendedStd_v3_2dg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd0d85da-81de-4b45-af95-d16ec0d4638d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 IC_SODA\n",
      "1 IT_SODA\n",
      "2 MLD_SODA\n",
      "3 OHC100_SODA\n",
      "4 OHC200_SODA\n",
      "5 OHC300_SODA\n",
      "6 OHC50_SODA\n",
      "7 OHC700_SODA\n",
      "8 OLR_ERA5\n",
      "9 SD_ERA5\n",
      "10 SSH_SODA\n",
      "11 SST_OISSTv2\n",
      "12 SST_SODA\n",
      "13 STL_1m_ERA5\n",
      "14 STL_28cm_ERA5\n",
      "15 STL_7cm_ERA5\n",
      "16 STL_full_ERA5\n",
      "17 SWVL_1m_ERA5\n",
      "18 SWVL_28cm_ERA5\n",
      "19 SWVL_7cm_ERA5\n",
      "20 SWVL_full_ERA5\n",
      "21 U10_ERA5\n",
      "22 U200_ERA5\n",
      "23 Z500_ERA5\n"
     ]
    }
   ],
   "source": [
    "for ivar,var in enumerate(list_vars):\n",
    "    print(ivar,var)\n",
    "    path_nc_anoms = f'{path_weekly_anoms}{var}.nc'\n",
    "    anoms = xr.open_dataset(path_nc_anoms)\n",
    "    anoms = anoms.assign_coords(time=pd.DatetimeIndex(anoms.time).normalize())\n",
    "    var_name_nc = list(anoms.data_vars.keys())[0]\n",
    "    resolution = 2 ## 1 degree\n",
    "    ### PROCESS AND LOAD DATA\n",
    "    if resolution == 0.5:\n",
    "        regridded_dataset = anoms\n",
    "    else:\n",
    "        regridded_dataset = regrid_dataset_3d(anoms, resolution)\n",
    "    regridded_dataset.to_netcdf(f'{path_weekly_anoms_1dg}{var}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fbf5a6-13e9-42be-9426-afc7f8d4426d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a3276-e29d-4f9b-8cd7-c7eec8d08105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960ed10-090c-4f8a-a5ef-e16823366881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_wr]",
   "language": "python",
   "name": "conda-env-pytorch_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
