{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db404b0-14cd-467b-98c5-b9a9f763775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from itertools import product\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.path as mpath\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.feature as cf\n",
    "import shapely.geometry as sgeom\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import string\n",
    "\n",
    "import pickle\n",
    "import copy\n",
    "from shapely import geometry\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8812ead-c427-4d1e-b22c-1a564617a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_climatology_smoothed(dataset, var_name_xarray, window=60):\n",
    "    # Subset dataset for the period 1981-2020\n",
    "    dataset_clima = dataset.isel(time=(pd.to_datetime(dataset.time).year >= 1981) &\n",
    "                                       (pd.to_datetime(dataset.time).year <= 2020))\n",
    "    \n",
    "    # Remove leap day (Feb 29)\n",
    "    dataset_clima = dataset_clima.isel(time=~((pd.to_datetime(dataset_clima.time).day == 29) &\n",
    "                                              (pd.to_datetime(dataset_clima.time).month == 2)))\n",
    "    \n",
    "    # Get the day of year (DOY)\n",
    "    doy = pd.to_datetime(dataset_clima.time).day_of_year\n",
    "    climatology = []\n",
    "\n",
    "    # Compute the daily mean for each day of the year\n",
    "    for i in range(1, 366):\n",
    "        daily_mean = dataset_clima.isel(time=doy == i)[var_name_xarray].mean('time')\n",
    "        climatology.append(daily_mean)\n",
    "    \n",
    "    # Convert to xarray Dataset with the appropriate dimensions\n",
    "    attrs = dataset[var_name_xarray].attrs\n",
    "    attrs['File Author'] = 'Jhayron S. Pérez-Carrasquilla'\n",
    "    \n",
    "    climatology = xr.Dataset({\n",
    "        f'{var_name_xarray}_climatology': (['day_of_year', 'lat', 'lon'], np.array(climatology)),\n",
    "    }, \n",
    "    coords={\n",
    "        'day_of_year': np.arange(1, 366),\n",
    "        'lat': dataset.lat.values,\n",
    "        'lon': dataset.lon.values,\n",
    "    },\n",
    "    attrs=attrs)\n",
    "\n",
    "    climatology = climatology.transpose('day_of_year', 'lat', 'lon')\n",
    "\n",
    "    # Stack climatology 3 times to handle edges\n",
    "    climatology_extended = xr.concat([climatology, climatology, climatology], dim='day_of_year')\n",
    "\n",
    "    # Adjust coordinates after stacking to represent a larger time span\n",
    "    climatology_extended['day_of_year'] = np.arange(1, 365 * 3 + 1)\n",
    "\n",
    "    # Apply rolling mean with a 60-day window for smoothing\n",
    "    climatology_smoothed = climatology_extended.rolling(day_of_year=window, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Extract the middle portion, corresponding to the original 365 days\n",
    "    climatology_smoothed = climatology_smoothed.isel(day_of_year=slice(365, 365 + 365))\n",
    "\n",
    "    # Reset 'day_of_year' coordinate to original range\n",
    "    climatology_smoothed['day_of_year'] = np.arange(1, 366)\n",
    "\n",
    "    return climatology_smoothed\n",
    "\n",
    "def get_anomalies(dataset,var_name_xarray,climatology):\n",
    "    anomalies = copy.deepcopy(dataset)\n",
    "    for day in range(1,367):\n",
    "        # print(day) \n",
    "        if day == 366:\n",
    "            anomalies[var_name_xarray][{'time':(pd.to_datetime(dataset.time).day_of_year == day)}] = \\\n",
    "                (dataset[var_name_xarray].isel(time = (pd.to_datetime(dataset.time).day_of_year == day)) \\\n",
    "                - climatology[f'{var_name_xarray}_climatology'].sel(day_of_year = day-1))\n",
    "        else:\n",
    "            anomalies[var_name_xarray][{'time':(pd.to_datetime(dataset.time).day_of_year == day)}] = \\\n",
    "                (dataset[var_name_xarray].isel(time = (pd.to_datetime(dataset.time).day_of_year == day)) \\\n",
    "                - climatology[f'{var_name_xarray}_climatology'].sel(day_of_year = day))\n",
    "    anomalies = anomalies.rename({var_name_xarray:f'{var_name_xarray}_anomalies'})\n",
    "    # anomalies.to_netcdf(path_save_anomalies)\n",
    "    return anomalies\n",
    "\n",
    "def get_climatology_std_smoothed(dataset, var_name_xarray, window=60):\n",
    "    # Remove leap day (Feb 29)\n",
    "    dataset_clima = dataset.isel(time = ~((pd.to_datetime(dataset.time).day == 29) & \n",
    "                                          (pd.to_datetime(dataset.time).month == 2)))\n",
    "    \n",
    "    # Get the day of year (DOY)\n",
    "    doy = pd.to_datetime(dataset_clima.time).day_of_year\n",
    "    climatology = []\n",
    "\n",
    "    # Compute the daily standard deviation for each day of the year\n",
    "    for i in range(1, 366):\n",
    "        array_temp = dataset_clima.isel(time=doy == i)[var_name_xarray]\n",
    "        std = np.nanstd(array_temp, axis=0)\n",
    "        std[std == 0] = np.nan\n",
    "        climatology.append(std)\n",
    "    \n",
    "    # Convert to xarray Dataset with the appropriate dimensions\n",
    "    attrs = dataset[var_name_xarray].attrs\n",
    "    attrs['File Author'] = 'Jhayron S. Pérez-Carrasquilla'\n",
    "    \n",
    "    climatology = xr.Dataset({\n",
    "        f'{var_name_xarray}_climatology_std': (['day_of_year', 'lat', 'lon'], np.array(climatology)),\n",
    "    }, \n",
    "    coords={\n",
    "        'day_of_year': np.arange(1, 366),\n",
    "        'lat': dataset.lat.values,\n",
    "        'lon': dataset.lon.values,\n",
    "    },\n",
    "    attrs=attrs)\n",
    "\n",
    "    climatology = climatology.transpose('day_of_year', 'lat', 'lon')\n",
    "    # print(climatology)\n",
    "    # Stack climatology 3 times to handle edges\n",
    "    climatology_extended = xr.concat([climatology, climatology, climatology], dim='day_of_year')\n",
    "\n",
    "    # Adjust coordinates after stacking to represent a larger time span\n",
    "    climatology_extended['day_of_year'] = np.arange(1, 365 * 3+1)\n",
    "\n",
    "    # Apply rolling mean with a 60-day window for smoothing\n",
    "    climatology_smoothed = climatology_extended.rolling(day_of_year=window, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Extract the middle portion, corresponding to the original 365 days\n",
    "    climatology_smoothed = climatology_smoothed.isel(day_of_year=slice(365, 365 + 365))\n",
    "\n",
    "    # Reset 'day_of_year' coordinate to original range\n",
    "    climatology_smoothed['day_of_year'] = np.arange(1, 366)\n",
    "\n",
    "    return climatology_smoothed\n",
    "\n",
    "\n",
    "def standardize_anomalies(anomalies,var_name_xarray,climatology_std):\n",
    "    std_anomalies = copy.deepcopy(anomalies)\n",
    "    for day in range(1,367):\n",
    "        # print(day) \n",
    "        if day == 366:\n",
    "            std_anomalies[var_name_xarray][{'time':(pd.to_datetime(anomalies.time).day_of_year == day)}] = \\\n",
    "                (anomalies[var_name_xarray].isel(time = (pd.to_datetime(anomalies.time).day_of_year == day)) \\\n",
    "                / climatology_std[f'{var_name_xarray}_climatology_std'].sel(day_of_year = day-1))\n",
    "        else:\n",
    "            std_anomalies[var_name_xarray][{'time':(pd.to_datetime(anomalies.time).day_of_year == day)}] = \\\n",
    "                (anomalies[var_name_xarray].isel(time = (pd.to_datetime(anomalies.time).day_of_year == day)) \\\n",
    "                / climatology_std[f'{var_name_xarray}_climatology_std'].sel(day_of_year = day))\n",
    "    # std_anomalies = std_anomalies.rename({var_name_xarray:f'{var_name_xarray}_anomalies'})\n",
    "    # std_anomalies.to_netcdf(path_save_anomalies)\n",
    "    return std_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500c9805-fb63-464b-9bc2-a924848f433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Function to compute the trend for a single pixel\n",
    "def compute_trend_for_pixel(args):\n",
    "    series_values, lat_idx, lon_idx = args\n",
    "    X = np.arange(len(series_values)).reshape(-1, 1)\n",
    "    y = series_values\n",
    "    \n",
    "    # Default value in case of failure\n",
    "    coef = 0\n",
    "    \n",
    "    try:\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        coef = model.coef_[0]\n",
    "    except Exception as e:\n",
    "        coef = np.nan  # You can also handle missing data this way if desired\n",
    "\n",
    "    return coef, lat_idx, lon_idx\n",
    "\n",
    "# Main function to compute trends in parallel\n",
    "def get_trend_multiprocessing(dataset, var_name_xarray, num_workers=8):\n",
    "    dataset_clima = dataset.isel(time=(pd.to_datetime(dataset.time).year >= 1981) &\n",
    "                                        (pd.to_datetime(dataset.time).year <= 2020))\n",
    "    \n",
    "    lat = dataset_clima.lat.values\n",
    "    lon = dataset_clima.lon.values\n",
    "    \n",
    "    # Prepare the list of arguments for each pixel (using NumPy arrays for time series)\n",
    "    args_list = []\n",
    "    for lati in range(len(lat)):\n",
    "        for loni in range(len(lon)):\n",
    "            series = dataset_clima.sel(lat=lat[lati], lon=lon[loni])[var_name_xarray].values\n",
    "            args_list.append((series, lati, loni))\n",
    "    \n",
    "    # Use multiprocessing to compute the trend for each pixel\n",
    "    with mp.Pool(processes=num_workers) as pool:\n",
    "        results = pool.map(compute_trend_for_pixel, args_list)\n",
    "    \n",
    "    # Create an empty array to store the coefficients\n",
    "    array_coefs = np.zeros([len(lat), len(lon)])\n",
    "    \n",
    "    # Reassemble the results\n",
    "    for coef, lati, loni in results:\n",
    "        array_coefs[lati, loni] = coef\n",
    "    \n",
    "    # Store the results in a Dataset with appropriate attributes\n",
    "    attrs = dataset[var_name_xarray].attrs\n",
    "    attrs['File Author'] = 'Jhayron S. Pérez-Carrasquilla'\n",
    "    attrs['units'] = f\"{attrs['units']}/day\"\n",
    "    \n",
    "    trend = xr.Dataset({\n",
    "        f'{var_name_xarray}_trend': (['lat', 'lon'], array_coefs),\n",
    "    },\n",
    "    coords={\n",
    "        'lat': (['lat'], lat),\n",
    "        'lon': (['lon'], lon)\n",
    "    },\n",
    "    attrs=attrs)\n",
    "    \n",
    "    return trend\n",
    "\n",
    "def detrend(dataset,var_name_xarray,trend):\n",
    "    dataset = dataset.isel(time = (pd.to_datetime(dataset.time).year>=1981))\n",
    "    lat = dataset.lat.values\n",
    "    lon = dataset.lon.values\n",
    "    X = np.array([i for i in range(0, len(dataset[f'{var_name_xarray}']))])\n",
    "    X_3d = np.repeat(X[:,None], len(lat), axis=1)\n",
    "    X_3d = np.repeat(X_3d[:,:,None],len(lon),axis=2)\n",
    "    rect_lines = X_3d * trend[f'{var_name_xarray}_trend'].values\n",
    "    rect_lines = rect_lines - np.mean(rect_lines,axis=0)\n",
    "    detrended_data = dataset[f'{var_name_xarray}']-rect_lines\n",
    "    dataset[f'{var_name_xarray}'] = detrended_data\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575fe759-b419-4df8-8b89-02ca27516700",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_daily_datasets = '/glade/derecho/scratch/jhayron/Data4Predictability/DailyDatasets/'\n",
    "list_datasets = np.sort(glob.glob(f'{path_daily_datasets}*.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "361b0606-016a-4264-ab93-920ceceb212f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cn_total\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/IC_SODA.nc\n",
      "1 hi\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/IT_SODA.nc\n",
      "2 mlt\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/MLD_SODA.nc\n",
      "3 ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC100_SODA.nc\n",
      "4 ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC200_SODA.nc\n",
      "5 ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC300_SODA.nc\n",
      "6 ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC50_SODA.nc\n",
      "7 ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC700_SODA.nc\n",
      "8 MTNLWRF\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OLR_ERA5.nc\n",
      "9 SD\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SD_ERA5.nc\n",
      "10 ssh\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SSH_SODA.nc\n",
      "11 sst\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SST_OISSTv2.nc\n",
      "12 temp\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SST_SODA.nc\n",
      "13 STL_1m\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_1m_ERA5.nc\n",
      "14 STL_28cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_28cm_ERA5.nc\n",
      "15 STL_7cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_7cm_ERA5.nc\n",
      "16 STL_full\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_full_ERA5.nc\n",
      "17 SWVL_1m\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_1m_ERA5.nc\n",
      "18 SWVL_28cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_28cm_ERA5.nc\n",
      "19 SWVL_7cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_7cm_ERA5.nc\n",
      "20 SWVL_full\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_full_ERA5.nc\n",
      "21 U\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/U10_ERA5.nc\n",
      "22 U\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/U200_ERA5.nc\n",
      "23 Z\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/Z500_ERA5.nc\n"
     ]
    }
   ],
   "source": [
    "for i_dataset in range(len(list_datasets)):\n",
    "    dataset_raw = xr.open_dataset(list_datasets[i_dataset])\n",
    "    path_anoms_final = list_datasets[i_dataset].replace('DailyDatasets','DailyDetrendedStdAnoms_v3')\n",
    "    \n",
    "    var_name_xarray = list(dataset_raw.data_vars.keys())[0]\n",
    "    print(i_dataset,var_name_xarray)\n",
    "    print(path_anoms_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064ff3da-ec4b-4063-850e-49d103305fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn_total\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/IC_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/IT_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlt\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/MLD_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC100_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC200_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC300_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC50_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocean_heat_content\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OHC700_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTNLWRF\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/OLR_ERA5.nc\n",
      "SD\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SD_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SSH_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SST_OISSTv2.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SST_SODA.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL_1m\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_1m_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL_28cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_28cm_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL_7cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_7cm_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL_full\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/STL_full_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWVL_1m\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_1m_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWVL_28cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_28cm_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWVL_7cm\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_7cm_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWVL_full\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/SWVL_full_ERA5.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1872: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/U10_ERA5.nc\n",
      "U\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/U200_ERA5.nc\n",
      "Z\n",
      "/glade/derecho/scratch/jhayron/Data4Predictability/DailyDetrendedStdAnoms_v3/Z500_ERA5.nc\n"
     ]
    }
   ],
   "source": [
    "for i_dataset in range(len(list_datasets)):\n",
    "    dataset_raw = xr.open_dataset(list_datasets[i_dataset])\n",
    "    path_anoms_final = list_datasets[i_dataset].replace('DailyDatasets','DailyDetrendedStdAnoms_v3')\n",
    "    \n",
    "    var_name_xarray = list(dataset_raw.data_vars.keys())[0]\n",
    "    print(var_name_xarray)\n",
    "    print(path_anoms_final)\n",
    "    \n",
    "    dataset_raw = dataset_raw.compute()\n",
    "    # Compute anomalies\n",
    "    clima = get_climatology_smoothed(dataset_raw,var_name_xarray)\n",
    "    anoms = get_anomalies(dataset_raw,var_name_xarray,clima)\n",
    "\n",
    "    # First detrend, then compute anomalies\n",
    "    trend = get_trend_multiprocessing(anoms, f'{var_name_xarray}_anomalies', num_workers=230)\n",
    "    data_detrended = detrend(anoms, f'{var_name_xarray}_anomalies', trend)\n",
    "    \n",
    "    clima_std = get_climatology_std_smoothed(data_detrended,f'{var_name_xarray}_anomalies')\n",
    "    std_anomalies = standardize_anomalies(data_detrended,f'{var_name_xarray}_anomalies',clima_std)\n",
    "    std_anomalies.to_netcdf(path_anoms_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
